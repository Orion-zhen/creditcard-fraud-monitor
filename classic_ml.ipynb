{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orion/share/coding/creditcard-fraud-monitor/.venv/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/orion/share/coding/creditcard-fraud-monitor/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/orion/share/coding/creditcard-fraud-monitor/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/orion/share/coding/creditcard-fraud-monitor/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/orion/share/coding/creditcard-fraud-monitor/.venv/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree accuracy: 0.9390862944162437\n",
      "knn accuracy: 0.9187817258883249\n",
      "lr accuracy: 0.9593908629441624\n",
      "svm accuracy: 0.8629441624365483\n",
      "rf accuracy: 0.9644670050761421\n",
      "xgb accuracy: 0.9543147208121827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# 下采样，使得两个样本同样少\n",
    "# Number of data points in the minority class\n",
    "number_records_fraud = len(data[data.Class == 1])  # 计算异常样本的个数\n",
    "fraud_indices = np.array(data[data.Class == 1].index)  # 异常样本在原数据的索引值\n",
    "\n",
    "# Picking the indices of the normal classes\n",
    "normal_indices = data[data.Class == 0].index  # 获得原数据正常样本的索引值\n",
    "\n",
    "# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\n",
    "random_normal_indices = np.random.choice(\n",
    "    normal_indices, number_records_fraud, replace=False\n",
    ")  # 通过索引进行随机的选择\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# Appending the 2 indices\n",
    "under_sample_indices = np.concatenate(\n",
    "    [fraud_indices, random_normal_indices]\n",
    ")  # 将class=1和class=0 的选出来的索引值进行合并\n",
    "\n",
    "# Under sample dataset\n",
    "under_sample_data = data.iloc[under_sample_indices, :]\n",
    "\n",
    "# 观察特征可视化后选择剔除部分特征\n",
    "droplist = [\n",
    "    \"V8\",\n",
    "    \"V13\",\n",
    "    \"V15\",\n",
    "    \"V20\",\n",
    "    \"V21\",\n",
    "    \"V22\",\n",
    "    \"V23\",\n",
    "    \"V24\",\n",
    "    \"V25\",\n",
    "    \"V26\",\n",
    "    \"V27\",\n",
    "    \"V28\",\n",
    "    \"Time\",\n",
    "]\n",
    "data_new = under_sample_data.drop(droplist, axis=1)\n",
    "\n",
    "# 切分训练集和测试集\n",
    "X = data_new.iloc[:, data_new.columns != \"Class\"]\n",
    "y = data_new.iloc[:, data_new.columns == \"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 建立模型\n",
    "\n",
    "# 1. 决策树\n",
    "tree_model = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_yhat = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# 2. k最近邻居\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)\n",
    "\n",
    "\n",
    "# 3. 逻辑斯蒂回归\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)\n",
    "\n",
    "\n",
    "# 4. 支持向量机\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)\n",
    "\n",
    "\n",
    "# 5. 随机森林\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# 6. XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)\n",
    "\n",
    "print(f\"tree accuracy: {accuracy_score(y_test, tree_yhat)}\")\n",
    "print(f\"knn accuracy: {accuracy_score(y_test, knn_yhat)}\")\n",
    "print(f\"lr accuracy: {accuracy_score(y_test, lr_yhat)}\")\n",
    "print(f\"svm accuracy: {accuracy_score(y_test, svm_yhat)}\")\n",
    "print(f\"rf accuracy: {accuracy_score(y_test, rf_yhat)}\")\n",
    "print(f\"xgb accuracy: {accuracy_score(y_test, xgb_yhat)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
